[l] Zu meinen KI-Überlegungen kamen ein paar interessante Kommentare rein. Erstens haben mir gleich mehrere Einsender die dicke Kroete zu schlucken gegeben, dass meine Befuerchtungen zum Gesundheitssystem schon laengst eingetroffen sind:Ich kann dir als Pharmaziestudent sagen, dass bereits heute JEDES MEDIKAMENT (!!!) von KI in gewissem Masse gemacht wird."Drug Design" bzw. die Suche nach Wirkstoffen funktioniert naemlich folgendermassen:Zunaechst sucht man den Liganden, der an den gewuenschten Rezeptor bindet. Da es unglaublich viele Molekuele gibt, muss zunaechst am Computer vorausgewaehlt werden. Diese Programme werden von Bioinformatikern geschrieben, die ausschliesslich KI benutzen. Woher ich das weiss? 90% der Programme sind zwar closed source (gehoeren der Pharmaindustrie), aber die, die es an der Uni gibt, nutzen neuronale Netze (http://www.mrupp.info/publications.html). Erst nachdem es die ersten "hits" gibt bzw. man eine Leitstruktur ausgesucht hat, wird mit rationaleren Methoden weitergearbeitet (z.b. unser Programm). Dies ist aber eigentlich auch nicht so toll, weil z.B. QSAR davon ausgeht, dass wenn wir gleiche Molekuelteile haben, diese stets aehnliche Wirkung haben. Dies fuehrt zum "QSAR paradox", das den Sachverhalt beschreibt, dass die Grundannahme nicht stimmt (Contergan! Nein! Doch! Oh!).Ich denke, dass es hier eine grosse Marktluecke gibt. Die guten Chemiker, die auch Ahnung von Quantenmechanik haben, arbeiten an Programmen, die kleine Molekuele sehr gut beschreiben/ Eigenschaften vorhersagen.Die "schlechteren" arbeiten u.a. bei uns in der Synthese und konkurrieren leicht mit den Pharmazeuten.Die Biophysiker beschaeftigen sich mit spektroskopischen Methoden von Biomolekuelen. Dies erfolgt rational und es werden auch Fortschritte erzielt.Die Bioinformatiker sind die einzigen, die sich mit Computermodellen von Proteinen usw. befassen, greifen aber fast ausschliesslich auf machine learning zurueck. Ich kenne nur eine Ausnahme: http://www.merzgroup.org/Hier noch ein Einsender, der in eine aehnliche Bresche schlaegt:a couple of thoughts of mine about Google's KI: you did mention neural networks and related things.  In medicinal chemistry people have been classifying chemical compounds for 30 years (!) using neural networks. It works extremely well - this one is toxic, that one isn't, this is a Glycoprotein P substrate, that one is not - even in prospective studies.  It's impossible to derive any rules from all of these studies but my thought has always been: if it were simple they wouldn't have to resort to neural networks.You also mentioned healthcare.  People are slowly waking up to the realities of systems biology.  It really isn't that there are metabolic cycles or feedback loops, biologial reality doesn't look like this at all.  What really happens is that there are all sorts of interacting networks of things, some of which may compensate for others.  This is how evolution works, after all, though gene duplication and repurposing of enzymes.  The whole fabric is already impossible to understand for any human and cannot be turned into a simple model.  Hence the very expensive realities of pharmaceutical R&D.  There was no reason to expect that COX-2 inhibitors would put those that take it at risk of heart disease, but it is a fact that they do.  No idea why.Dann gab es noch einen schoenen Kommentar aus der Sci-Fi-Ecke:Du sagst im Grunde, dass der Mensch die hoechste Intelligenz auf diesem Planeten war und ist, und folgerst, dass er es selbstverstaendlich auch bleiben sollte. Wir Menschen verwenden einen Gutteil unserer Ressourcen darauf uns zu reproduzieren und das beste aus unserem Nachwuchs zu machen. Wenn wir nun ploetzlich in der Lage sind ein System zu erschaffen, das uns intellektuell ueberfluegelt, dann sollten wir vielleicht aufhoeren uns zu reproduzieren und unsere Ressourcen in die Entwicklung dieses "besseren" Systems stecken. Fuer mich klingt das nach dem logisch naechsten Schritt in der Evolution. Das Thema ist nur hochgradig angstbesetzt.und weiter (war eine sehr lange Zuschrift, ich gebe daher aus Platzgruenden nur Teile wieder):In der KI-Forschung ist die Frage der Vorhersagbarkeit solcher Systeme (beider Varianten) natuerlich schon ausgiebigst diskutiert worden. Das Ergebnis ist ein interessantes Paper namens "Structural Risk Minimization", das besagt: Je mehr (Lern)Kapazitaet ein Modell hat, desto hoeher ist das Risiko, dass es "was falsches" lernt, also einen Generalisierungsfehler macht. Und umgekehrt: Je mehr "widerspruechliche" Daten von einem lernenden System korrekt gelernt werden koennen sollen, desto hoeher ist die benoetigte Kapazitaet.Fuer diese Kapazitaet gibt es auch ein Mass, und zwar die sog. VC-Dimension. Die VC-Dimension ist genau die maximale Anzahl an Datenpunkte, fuer ein Lerner - unabhaengig von der  Faerbung der Datenpunkte - ein Modell (Programm) ausspuckt, das diese Punkte korrekt klassifiziert.Zurueck uebertragen auf deine Frage mit der KI-basierten Softwareentwicklung: Da von einer KI derzeit nur Programme entwickelt werden koennen, die auf endlichen Eingabedaten funktionieren, kann man die so entwickelten Programme auch leicht daraufhin ueberpruefen, ob sie die Eingabedaten korrekt wiedergeben. Man enthaelt der KI einfach einen Teil der Eingabedaten vor und prueft anhand derer das resultierende Programm. Wenn die Fehlerquote signifikant ueber der gemaess VC-Dimension zu erwartenden Fehlerrate liegt, ist das Programm falsch. Und das war's dann auch schon.Der Ansatz, dass ein Mensch ein von einer KI entwickeltes Programm "semantisch" ueberprueft, ist nur insoweit zielfuehrend, wie die von der KI entwickelten Programme ueberhaupt Semantik verarbeiten. Und wenn sie das tun, sind die Ableitungen der Regeln, die diese Programme vornehmen (wie in Prolog) fuer einen Menschen auch wieder nachvollziehbar.Dann kam noch dieser Link rein (es geht um genetische Algorithmen im Chipdesign, Ctrl-F baffling fuer den spannenden Teil)Und zuletzt weisen einige Einsender darauf hin, dass AlphaGo mitnichten einfach ein neuronales Netz ist, sondern schon auch "normale" Monte-Carlo-Baumsuche verwendet, aber halt unterstuetzt mit neuronalen Netzen. Einer kommentiert noch:Ich stelle mir den menschlichen Go-Spieler wie einen Ingenieur vor, der ohne Hilfsmittel arbeitet. Die Google-KI ist dagegen ein Ingenieur, der einen Rechenschieber oder einen Taschenrechner (ein an sich nicht intelligentes, aber schnell und praezise arbeitendes Hilfsmittel) direkt ins Gehirn implantiert hat.Ein Beispiel ist Zug 108 der ersten Partie gegen Lee Sedol: Dieser Zug ist vielleicht keiner der besonders „komischen Zuege“, aber ein menschlicher Spieler haette diesen Zug niemals gemacht, denn er ist aus seiner Perspektive riskant. Die moeglichen Konsequenzen sind komplex und vielfaeltig, und es ist schwierig abzuschaetzen, ob wirklich alle sich ergebenden Varianten fuer den Spieler von Vorteil sind. Die Google-KI hingegen wirft ihren Monte-Carlo-Taschenrechner an und kann mit hinreichender Sicherheit feststellen, dass dieser Zug eben kein Fehler ist. Auf diese Weise verbindet AlphaGo die „Intuition“ seiner neuronalen Netze mit mehr oder weniger klassischer Vorausberechnung der Zuege.Der „Fehler“ des Menschen, weshalb er verliert, ist also so gesehen, auf die „riskant“ aussehenden, aber in Wahrheit sicheren Zuege verzichten zu muessen und statt dessen die offensichtlich sicheren, aber nicht ganz so guten Zuege zu spielen.Ein Einsender hat mir noch Mut zuzusprechen versucht, indem er Parallelen zur Mechanik zieht.Frueher hat man mechanische Bauteile -z.B. Schubstangen oder Pleuel- nach Erfahrung ausgelegt. Spaeter kam ein mathematisches Modell zur Beschreibung der Bauteile (Eulersche Knickfaelle). Noch sehr viel spaeter hat man dann das Modell nach innen gelegt (kleine Gitterzellen FEM) und mit den Ergebnissen daraus das aeussere Modell daran angepasst.Wir koennen immer noch nicht sagen, warum dieses eine Pleuel genau an dieser Stelle geknickt/gebrochen ist. Wir koennen nur sagen, dass es mit hoher Wahrscheinlichkeit an dieser Stelle wegen diesem Lunker, dieser Kerbwirkung, dieser Resonanz versagt hat (insbesondere bei Resonanzen bin ich mir sicher, dass das nur ca 1/5 der Ingenieure versteht, bei Torsionsresonanzen nochmal die Haelfte weniger).Wir koennen es beschreiben, und seit einiger Zeit so gut, dass es fast keine weiteren Forschungsgelder mehr fuer Mechanik gibt, weil nichts grundlegend neueres erwartet wird.und zur Frage der Debugbarkeit meint er, das ginge bei Mechanik ja auch nicht. Da kann man das Teil nur anders auslegen und neu bauen.
