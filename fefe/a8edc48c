[l] Ist euch mal aufgefallen, dass mein Blog relativ schnell laedt? Wahrscheinlich.Habt ihr euch auch mal gefragt, warum dass so ist? Ist meine Anbindung so toll? Meine Hardware? Meine Software? Cache ich so krass?Nein. Ich cache hier nichts. Jede Anfrage, die reinkommt, erzeugt und beendet zwei Prozesse und eine Kette aus 4 Interprozess-Kommunikationen. Es gibt kein memcache, keinen Varnish, kein Load-Balancer, kein Cassandra, kein Akamai, nichts. Der einzige Grund, wieso das bei mir flutscht, ist weil ich die Anzahl der HTTP-Anfragen minimiert habe und nichts externes reinlade. Bei mir kommt es im Allgemeinen bei einem Zugriff zu drei HTTP-Requests. Einmal das HTML selbst, einmal das favicon, und einmal das CSS, wenn ihr eines einbindet. favicon und CSS sind statisch und muessen normalerweise nicht neu uebertragen werden. Bleibt als einziger Inhalt das HTML. Das komprimiere ich vor der Ãœbertragung, und benutze auch kein CMS, was das irgendwie aufblaehen koennte. Hier gibt es kein Typekit, kein React, kein jquery, keine Facebook-Buttons, etc.Das mag jetzt trivial erscheinen, aber ueberlegt euch mal folgendes. Nehmen wir mal an, eine Webseite besteht aus 100 Elementen. Der Webserver bei einem davon hat einen Schluckauf und braucht 10 Sekunden. Dann laedt die Seite gefuehlt langsam. Mal ganz abgesehen von der riesigen Datenmenge, versteht sich, die durch so viele Elemente entstehen. Alleine die Header sind ja schon 2 KB pro Anfrage.Mein Webserver hat bestimmt auch gelegentlich mal einen schlechten Request, der aus irgendeinem Grund langsam ist. Wenn bei mir jeder 1000. Request gammelig ist, betrifft das nicht mal jeden hundersten User. Wenn bei einer Site mit 100 Elementen jeder 1000. Request gammelig ist, betrifft das jeden Zehnten.Ich erwaehne das alles bloss als Einleitung fuer eine Video-Empfehlung: Ein Talk darueber, wie man Latenz misst. Es geht um den Web-Kontext. Die Kurzzusammenfassung ist: Fast alle machen es falsch. Ihr wahrscheinlich auch. Ausser ihr habt eure Messtools selber gehackt, und selbst dann moeglicherweise immer noch.Ich habe uebrigens in gatling damals das Logformat extra so gemacht, dass das eine angesprochene Problem nicht deshalb nicht messbar ist, weil die vorliegenden Daten es nicht zulassen. Vielleicht sollte ich meine Ad-Hoc-Messtools mal ein bisschen professionalisieren und veroeffentlichen, wenn die Tool-Situation wirklich so uebel ist, wie er in dem Vortrag sagt.
