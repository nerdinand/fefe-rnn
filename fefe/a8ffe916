[l] Weniger bekannt als andere Abteilungen bei Google ist die Abteilung fuer Kompressionsalgorithmen, wo einige helle Koepfe arbeiten. Deren erste wichtiger Errungenschaft war Zopfli, die im Format von zlib/gzip bleibt, viel langsamer ist, aber dafuer geringfuegig hoehere Kompression rausholt. Fuer den Fall, in dem man nur einmal komprimiert und dann tausendfach liest, lohnt sich das moeglicherweise.Jetzt haben sie Brotli offiziell veroeffentlicht, das ist der Algorithmus, den sie schon in WOFF2 verwendet haben. Sie sagen, der sei grob so schnell wie deflate von zlib, aber komprimiert geringfuegig besser als LZMA und bzip2 beim Canterbury corpus (ein Standardkorpus aus verschiedenen Text- und Binaerdateien).Dass deren Algorithmen alle wie schweizer Teigwaren klingen, liegt wohl daran, dass das Team in der Schweiz sitzt?Wenn ihr schon mal am Rumfummeln mit Kompressionslibraries seid, kann ich noch miniz und lzham empfehlen. miniz ist ein drop-in-Ersatz fuer zlib, der nur aus einer Datei besteht. lzham ist ein Codec fuer Spieleprogrammierer, eine Variante von lzma. Komprimiert geringfuegig schlechter als lzma, die Kompression ist vergleichbar schnell, aber dekomprimiert sogar schneller as zlib. Damit das mit dem "schneller als zlib" klappt, muss man allerdings mindestens 64k oder so am Stueck dekomprimieren. Das ist genau der Trade-Off, den man als Spieleentwickler haben will. Da ist Dekompressionsgeschwindigkeit besonders wichtig, aber man will auch ordentliche Kompression haben. Ich plane seit einiger Zeit, lzham mal in meinen komprimierenden Volltextindexcode einzubauen statt miniz. Ich denke, da wuerde das auch ein perfekt passen.Wer haette gedacht, dass sich bei Kompressionsverfahren noch mal was tun wuerde? Das schien seit ein paar Jahren fast komplett zu stagnieren.
