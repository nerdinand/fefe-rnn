[l] Ist euch mal aufgefallen, dass grep -n langsamer ist als grep ohne -n?  Das liegt daran, dass grep ohne -n beim Suchen nach einer Zeichenkette ein sehr cooles Verfahren namens Boyer-Moore anwenden kann.  Bei Boyer-Moore (es gibt davon noch Varianten) muss man sich diverse Zeichen gar nicht erst angucken.  Sagen wir mal, wir suchen nach "fnord".  Dann wuerde die naive Suche nach "f" suchen, und wenn eines gefunden wurde, gucken, ob dahinter ein "nord" kommt.  Boyer-Moore wuerde sich zuerst das 5. Zeichen angucken.  Wenn da z.B. ein "z" steht, was im Suchbegriff gar nicht vorkommt, dann kann man es sich sparen, die anderen vier Zeichen davor anzugucken.  So kann man sich bis zu 4/5 des Aufwandes sparen bei einem Suchbegriff der Laenge 5.Eines meiner Projekte ist eine Suchmaschine fuer Code.  Damit indiziere ich dann den Quellcode bei Kundenprojekten, damit ich schnell darin herumnavigieren kann.  Fuer kleinere Codebasen lohnt sich das nicht, da macht man lieber grep -r und hat die Quellen in einer Ramdisk.  Aber bei manchen Kunden ist der Quellcode im hoeheren zweistelligen Gigabytebereich.  Da braucht man dann schon einen Index.Wenn ich in meinem Index jetzt nach einem Wort sucht, und im Allgemeinfall ist das ein Bezeichner aus dem Quellcode, d.h. ein laengeres Wort, dann sagt mir mein Index die Namen der Dateien, in denen das Wort vorkommt.  Aber ich will ja nicht nur wissen, in welchen Dateien es ist, sondern auch die Zeilennummer, damit ich da schoen hinnavigieren kann.Mein Code muss daher die Datei oeffnen und darin nach dem Wort suchen und mir dann die Trefferzeilen mit Zeilennummer ausgeben.  Wenn ich die Zeilennummer ausgeben will, kann ich aber nicht Boyer-Moore verwenden und dann Zeichen in der Mitte ueberspringen.  Daher wird die Suche langsamer.Das war der Grund, wieso ich gestern mal mit der Frage verbracht habe, wie man moeglichst schnell die Newlines in einem Speicherblock zaehlen kann.  Wenn es naemlich gelingt, die Newlines in einem Speicherblock effizienter als durch zeichenweises Lesen zu zaehlen, dann ist es moeglicherweise effizienter, erst mit Boyer Moore nach dem Match zu suchen und dann im Speicher davor nochmal die Newlines zu zaehlen.Damit das klappt, muesste man deutlich effizienter zaehlen.  Um zu verstehen, wie man effizienter sein kann, als jedes Byte einmal kurz anzugucken, muss man die Speicherhierarchie in CPUs verstehen.  Die CPUs sind heutzutage rasend schnell, aber der Speicher ist vergleichsweise langsam.  CPUs haben mehrere Hierarchien von Zwischenspeichern, aber selbst die sind noch langsam.  Wenn man ein Byte aus dem schnellsten (und kleinsten) Cache liest, dem Level 1-Cache, dann hat man immer noch pro Zugriff eine Straflatenz zu erdulden, bis der Wert vorliegt.  Auf meinem etwas aelteren AMD-Desktop war es ein Taktzyklus, bei einem modernen i7 ist es offenbar eher 2 oder 3.  Wie sich rausstellt ist diese Latenz aber nicht pro Byte sondern pro Zugriff.  Wenn man also mehr als ein Byte auf einmal liest, dann zahlt man diese Strafsteuer nur einmal.  Auf einer 64-bit-Architektur passen in ein Maschinen-Register 8 Bytes rein.  Die Kosten fuer Newlinezaehlen waeren damit also potentiell ein Achtel dessen, was man fuer die naive Implementation zahlt.  Zum Vergleich:size_t byfoot(const char* s,size_t l) {  size_t i,r;  for (i=r=0; i<l; ++i)    if (s[i]==n) ++r;  return r;}Das ist die naive Implementation.  Die braucht fuer eine 5k-Datei ca. 15000 CPU-Zyklen auf einem 4000er i7.Der erste Verbesserungsansatz waere, dass man wortweise liest und dann innerhalb des Wortes die Bytes einzeln rausmaskiert zum Vergleichen.size_t byfoot2(const char* s,size_t l) {
  size_t i,r;
  for (i=r=0; i+sizeof(i)<=l; i+=sizeof(i)) {
    size_t x=*(size_t*)(s+i);
    while (x) {
      r += ((x&0xff) == 0x0a);
      x >>= 8;
    }
  }
  for (; i<l; ++i)
    if (s[i]==n) ++r;
  return r;
}Hier haben wir pro Byte deutlich mehr Operationen, aber die laufen alle innerhalb der CPU asynchron ab, und es bleibt noch Zeit uebrig, um auf den Speicher zu warten.  Hiermit bin ich schon runter auf 11800 CPU-Zyklen.Wenn man noch mehr Performance will, muss man tricksen.  Die beste Variante, die ich dafuer gestern gefunden habe, ist die hier:static size_t fold(size_t v) {
  return (v * (size_t)0x0101010101010101) >> (sizeof(v)*8-8);
}

static size_t nlto1(size_t v) {
  v ^= (size_t)0x0a0a0a0a0a0a0a0a;
  v |= (v & (size_t)0x0101010101010101ull) << 1;
  v = ((v - (size_t)0x0101010101010101ull) & ~v & (size_t)0x8080808080808080ull);
  return v >> 7;
}

size_t newlines(const char* s,size_t l) {
  size_t i,n=0,r=0,max=l/sizeof(n);
  size_t* S=(size_t*)s;
  int o=255;
  for (i=0; i<max; ++i) {
    n += nlto1(S[i]);
    if (!--o) {
      r += fold(n);
      n=0;
      o=255;
    }
  }
  r += fold(n);
  if (l %= sizeof(i)) {
    s += i*sizeof(n);
    for (; l; --l)
      r += (*s++=='\n');
  }
  return r;
}Ich habe mal die Kommentare entfernt, weil ich mir dachte, dass vielleicht der eine oder andere von euch Spass daran haben koennte, zu verstehen, wie das funktioniert, und warum jeder einzelne Schritt davon da ist und noetig ist.  Mit diesem Code bin ich fuer die selben Daten schon runter auf 5200 Zyklen.  Nicht schlecht!  Geht aber noch besser.  Moderne CPUs haben Vektorinstruktionen fuer sowas, und mit SSE komme ich auf 2500 Zyklen.  Ich vermute, dass auch damit noch nicht das Ende der Fahnenstange erreicht ist.Wenn jemand eine klarere oder schnellere Variante des portablen Codestuecks findet, bitte ich um eine Email mit den Details!Die mir wichtige Lektion an der Stelle ist jedenfalls, dass Performance auf heutigen CPUs fast ausschliesslich eine Frage von "wieviel Speicherzugriffe habe ich" ist.  Unter dem Gesichtspunkt muss man auch Datenstrukturen bewerten.Update: Oh, einer noch.  Das da oben ist im 64-bit-Modus.  Im 32-bit-Modus lohnt sich das Bitgefrickel nur wenig bis gar nicht, da ist in meinem Messungen die zweite Variante von oben sogar geringfuegig schneller als die dritte.  Dafuer braucht spannenderweise der selbe SSE-Code nur noch 1800 Zyklen.  Keine Ahnung, wie das kommt.Es gibt uebrigens auch noch eine Bitfrickel-Variante von fold:static size_t fold(size_t v) {  v=(v & (size_t)0x00ff00ff00ff00ff) + ((v>>8) & (size_t)0x00ff00ff00ff00ff);  v=(v & (size_t)0x0000ffff0000ffff) + ((v>>16) & (size_t)0x0000ffff0000ffff);  if (sizeof(v)>4)    v = (v & 0xffffffff) + (v>>32);  return v;}Die ist aber geringfuegig langsamer bei mir.  Das haengt von der Performance der Integer-Multiplikationseinheit ab.  Auf anderen CPUs ist moeglicherweise das Bitfrickeln schneller.Update: Wie das erste Adlerauge (Glueckwunsch!) schon gemerkt hat, hat die Nicht-Bitfrickel-Fold-Funktion ein Overflow-Problem, wenn zu viele Newlines auf einmal reinkommen.  Das ist leider nicht so einfach zu fixen.  Ich verwendet daher gerade die Bitfrickel-Funktion, auch wenn das in der Praxis so gut wie nicht vorkommt in Code.  Ich wollte euch den Fold-Code trotzdem nicht vorenthalten, weil er so schoen bewusstseinserweiternd ist.
