[l] Ergebnisse von Filesystem-Fuzzing unter Linux. Das ist ein voellig unterbelichtetes Sicherheitsrisiko, das von vielen Leuten seit vielen Jahren ignoriert wird.Und frueher war das vielleicht mal ein Argument. Als man fuer den Einbau einer Festplatte noch SCSI-Kabel legen und eine Blutspende des Admins abgeben musste.Selbst wenn boesartige USB-Sticks in aller Munde sind, endet die Debatte haeufig bei Autoruns. Aber was wenn da jemand ein boesartiges Filesystem drauftut? Ich persoenlich fand ja, dass das schon seit iSCSI und Fibre Channel und so nicht mehr wegzudiskutieren ist als Problemklasse.Und so freut es mich sehr, dass es da jetzt einen konzertierten Anlauf gibt, die Filesysteme unter Linux mal robuster zu machen. Es geht ja nicht nur um Security. Man will ja auch nicht, dass der Kernel panict, nur weil auf einer alten Gammelplatte ein paar Bits geflippt sind.Die Ergebnisse sind ungefaehr, wie ich sie erwartet haette. ext4 hat am laengsten durchgehalten (deshalb setze ich das auch ueberall ein). Am schnellsten ist btrfs gestorben. XFS hielt erstaunlich lange durch, aber nicht so lange wie ext4. Naja und die ganzen Novelty-Filesysteme sterben natuerlich alle recht schnell. Da sind die Autoren ja froh, wenn der Code durch-kompiliert.Man muss dazu sagen, dass das nicht einfach nur ein Dumb Fuzzer war, sondern AFL, das ist ein adaptiver Fuzzer mit einer Art genetischem Programmieren. Der instrumentiert den Code und baut dann Testcases, um die Coverage zu maximieren, um jede Kombination aus Codepfaden mal genommen zu haben. Das Ding ist State of the Art. Wenn Code das ueberlebt, haben die Programmierer was richtig gemacht.
