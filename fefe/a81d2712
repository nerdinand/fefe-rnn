[l] Googles KI fuehrt jetzt 3-0 in ihrem 5-Partien-Go-Match gegen den menschlichen Grossmeister.Ich habe nicht viel Ahnung von Go, aber ich habe mir mal ein paar Kommentare durchgelesen. Und mein Eindruck ist, dass wir gerade eine Zeitenwende erleben.Bei Schach war das so, dass die Computer halt mehr Stellungen voraus probieren konnten, und sie haben gewonnen, weil die Menschen Fehler gemacht haben. Kommentatoren haben sich das angeguckt und konnten auf den Zug zeigen und sagen: Das war ein Fehler. Das hat dich die Partie gekostet.Aber bei Go gerade ist das anders. Die KI hat eine bessere Bewertungsfunktion als wir Menschen gefunden. Die Kommentatoren gucken sich die Parteien an und verstehen nicht, wieso die KI gewonnen hat. Der Mensch hat doch genau richtig gespielt! Der hat alles richtig gemacht, und dann hat die KI diesen komischen Zug hier gemacht, und dann hat der Mensch ploetzlich verloren.So, glaube ich, fuehlt sich so ein Sci-Fi-Szenario an, in dem eine ueberlegene ausserirdische Intelligenz die Erde angreift, und wir sind nicht schlau genug, ihre Strategie zu verstehen. Wir sehen, was sie tut, aber wir verstehen es nicht.Das ist uebrigens auch der Grund, wieso ich neuronale Netze und KI nie eine gute Forschungsrichtung fand. Wenn man so eine Software trainiert, und sie tut dann Dinge, dann kann man nicht daraus lernen, was sie genau gelernt hat, und das dann auch so tun. Man kann nur daneben sitzen und vielleicht einzelne Perzeptronen oder so beobachten, und sich sozusagen am Feuerwerk erfreuen, aber verstehen, was da passiert, und warum es passiert, das geht halt nicht. Fehler debuggen geht auch nicht. Man kann nur mehr oder neu trainieren.Und jetzt haben wir den Salat. Gluecklicherweise „nur“ bei Go. Bei Go halte ich uns Menschen fuer grundsaetzlich in der Lage, durch Beobachtung und Gehirnschmalz herauszuforschen, wieso wir gerade deklassiert wurden. Aber der Weg ist sehr gefaehrlich, den wir da gehen.Man stelle sich mal vor, ueberlegene KI wird sagen wir mal im Gesundheitssystem eingesetzt, tut 15 mysterioese Schritte und heilt damit Patienten. Und hat dann Nebenwirkungen, und wir verstehen gar nicht die Herleitung.Oder noch schlimmer (und das halte ich fuer eine sehr reale Gefahr): KI entwickelt eines Tages Software. Wir haben schon Probleme, von Menschen geschriebene Software spaeter zu verstehen und zu warten. Man stelle sich mal vor, die Software tut Dinge, die keiner erklaeren kann, weil die von einer KI geschrieben wurde.Und das uebelste an dem Gedankengang: Wir haben diese Art von Problem jetzt schon, ganz ohne KI. Voellig ohne Not.Wir sind halt doof, so als Spezies.Update: Wobei, „auch so tun“ kann man schon. Das war falsch ausgedrueckt. Aber verbessern kann man halt nicht. Eingreifen. Kontrolle hat man nicht mehr. Das ist wie ein Vergleich von Ingenieur und Kindergaertner. Man baut nichts mehr, sondern man erzieht eine KI. Wenn die dann das richtige tut — gut. Wenn nicht, dann hat man halt Pech.
